{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Transfer-Learning\" data-toc-modified-id=\"Transfer-Learning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Transfer Learning</a></div><div class=\"lev1 toc-item\"><a href=\"#save_bottlebeck_features()\" data-toc-modified-id=\"save_bottlebeck_features()-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>save_bottlebeck_features()</a></div><div class=\"lev1 toc-item\"><a href=\"#또는-직접-불러-오기\" data-toc-modified-id=\"또는-직접-불러-오기-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>또는 직접 불러 오기</a></div><div class=\"lev1 toc-item\"><a href=\"#train_top_model()\" data-toc-modified-id=\"train_top_model()-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>train_top_model()</a></div><div class=\"lev1 toc-item\"><a href=\"#Transfer-Learning-&amp;-fine-tuning\" data-toc-modified-id=\"Transfer-Learning-&amp;-fine-tuning-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Transfer Learning &amp; fine tuning</a></div><div class=\"lev2 toc-item\"><a href=\"#방법-1-:-Bottleneck-Feature-사용하지-않기\" data-toc-modified-id=\"방법-1-:-Bottleneck-Feature-사용하지-않기-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>방법 1 : Bottleneck Feature 사용하지 않기</a></div><div class=\"lev2 toc-item\"><a href=\"#방법-2:-Bottle-Feature-사용\" data-toc-modified-id=\"방법-2:-Bottle-Feature-사용-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>방법 2: Bottle Feature 사용</a></div><div class=\"lev1 toc-item\"><a href=\"#학습-수행\" data-toc-modified-id=\"학습-수행-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>학습 수행</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Transfer Learning\n",
    "\n",
    "![](http://i.imgur.com/1RvG7sN.jpg)\n",
    "\n",
    "참고 자료 \n",
    "- [Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "- [classifier_from_little_data_script_1.py](https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n",
    "- [classifier_from_little_data_script_2.py](https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069)\n",
    "- [classifier_from_little_data_script_3.py](https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975)\n",
    "\n",
    "[neocortex](https://github.com/neocortex/keras-transfer-learning)의 구현\n",
    "- 모델 직접 정의 하여 학습 \n",
    "- [03_using_bottleneck_features.ipynb](https://github.com/neocortex/keras-transfer-learning/blob/master/03_using_bottleneck_features.ipynb)\n",
    "- [04_fine_tuning.ipynb](https://github.com/neocortex/keras-transfer-learning/blob/master/04_fine_tuning.ipynb)\n",
    "- [05_classify_inria.ipynb](https://github.com/neocortex/keras-transfer-learning/blob/master/05_classify_inria.ipynb)\n",
    "\n",
    "Prakash의 구현\n",
    "- [Post](https://medium.com/towards-data-science/transfer-learning-using-keras-d804b2e04ef8)\n",
    "- [GitHUb](https://github.com/Prakashvanapalli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:48:39.037292Z",
     "start_time": "2017-05-05T14:48:39.031267Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:40:20.944960Z",
     "start_time": "2017-05-05T14:40:20.941331Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFLow Version:1.1.0\n",
      "Keras Version:2.0.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(\"TensorFLow Version:\"+str(tf.__version__))\n",
    "import keras; print(\"Keras Version:\"+str(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:49:15.875913Z",
     "start_time": "2017-05-05T14:49:15.865283Z"
    },
    "run_control": {
     "frozen": false,
     "marked": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow : Channel Last(150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# dimensions of our images.\n",
    "\n",
    "top_model_weights_path = 'fc_model.h5'\n",
    "train_data_dir = 'dog-cat/train'\n",
    "validation_data_dir = 'dog-cat/val'\n",
    "nb_train_samples = 2222 #2000 \n",
    "nb_validation_samples = 222 #800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "from keras import backend as K\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "    print(\"Theano : Channel First\"+str(input_shape))\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    print(\"TensorFlow : Channel Last\"+str(input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# save_bottlebeck_features()\n",
    "- bottleneck_features는 FC가 없는 VGG16 모델을 가지고 predict()한 값 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:09:49.648973Z",
     "start_time": "2017-05-04T22:09:49.331823Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the VGG16 network\n",
    "model = applications.VGG16(include_top=False, weights='imagenet', input_shape=input_shape) ## TF / TH구분으로 inputshape는 지정 필요\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# 또는 직접 불러 오기 \n",
    "\n",
    "``` python\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "\n",
    "# build the VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=input_shape #input_shape=(3, img_width, img_height)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:03:07.846178Z",
     "start_time": "2017-05-04T21:58:30.639208Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2222 images belonging to 2 classes.\n",
      "Found 222 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "#train_data\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "#validation_data\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
    "bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples // batch_size)\n",
    "#4분 cpu12-mem20-cost0344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "?? bottleneck_features를 생성(predict)할때 FC가 없는 불완전한 모델(include_top=False)로 하는것이 맞는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:13:34.317743Z",
     "start_time": "2017-05-04T22:13:34.025668Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "    bottleneck_features_train)\n",
    "np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "    bottleneck_features_validation)\n",
    "\n",
    "#write() argument must be str, not bytes 에러시   'w' ->'wb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# train_top_model()\n",
    "- top_model_weights는 `FC레이어`만있는 모델을 학습한 결과의 weight\n",
    "- 학습시 사용하는 데이터는 bottleneck_features이다. \n",
    "    - bottleneck_features는 FC가 없는 VGG16 모델을 가지고 `predict()`한 값 이다. \n",
    "    - bottleneck을 사용하는 이유는 FC만 학습 한다고 해도 모델이 크면 시간이 많이 걸리므로 학습(fit)이 아닌 빠른 예측(predict) 값을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:09.303034Z",
     "start_time": "2017-05-04T22:28:09.258393Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data = np.load(open('bottleneck_features_train.npy', 'rb')) #'rb'추가\n",
    "train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "# can't multiply sequence by non-int of type 'float' : 해결책  / -> //\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:11.750121Z",
     "start_time": "2017-05-04T22:28:11.746852Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#강제 데이터 - 라벨 수 맞춤\n",
    "train_labels = train_labels[0:2190]\n",
    "validation_labels = validation_labels[0:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:25:23.627665Z",
     "start_time": "2017-05-04T22:25:23.619366Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:20.174388Z",
     "start_time": "2017-05-04T22:28:20.135854Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:21.196322Z",
     "start_time": "2017-05-04T22:28:21.191239Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:24.773768Z",
     "start_time": "2017-05-04T22:28:24.743969Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:30:16.640127Z",
     "start_time": "2017-05-04T22:28:53.600085Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2190 samples, validate on 206 samples\n",
      "Epoch 1/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6972 - acc: 0.4886 - val_loss: 0.6910 - val_acc: 0.5485\n",
      "Epoch 2/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6934 - acc: 0.4858 - val_loss: 0.6931 - val_acc: 0.5388\n",
      "Epoch 3/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6928 - val_acc: 0.5388\n",
      "Epoch 4/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6927 - val_acc: 0.5388\n",
      "Epoch 5/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6925 - val_acc: 0.5388\n",
      "Epoch 6/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6924 - val_acc: 0.5388\n",
      "Epoch 7/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6923 - val_acc: 0.5388\n",
      "Epoch 8/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 9/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 10/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 11/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 12/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 13/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 14/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 15/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 16/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 17/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 18/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 19/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 20/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6923 - val_acc: 0.5388\n",
      "Epoch 21/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6923 - val_acc: 0.5388\n",
      "Epoch 22/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 23/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 24/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 25/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 26/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 27/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 28/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 29/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 30/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 31/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 32/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 33/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 34/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 35/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 36/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 37/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 38/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 39/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 40/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 41/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 42/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 43/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 44/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 45/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 46/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 47/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 48/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 49/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 50/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1aa411a8d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:30:50.655955Z",
     "start_time": "2017-05-04T22:30:50.627477Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Transfer Learning & fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## 방법 1 : Bottleneck Feature 사용하지 않기\n",
    "- top_model_weights를 사용하지 않고 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:49:29.587535Z",
     "start_time": "2017-05-05T14:49:29.281384Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:49:30.158253Z",
     "start_time": "2017-05-05T14:49:30.136316Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(200, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:49:31.107675Z",
     "start_time": "2017-05-05T14:49:31.104577Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Model(base_model.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:50:33.012721Z",
     "start_time": "2017-05-05T14:50:33.009782Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "#for layer in model.layers[:5]:\n",
    "#    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:50:39.592422Z",
     "start_time": "2017-05-05T14:50:39.569910Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "> 학습 수행 부분으로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## 방법 2: Bottle Feature 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:48:52.476321Z",
     "start_time": "2017-05-05T14:48:52.160100Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:48:53.092154Z",
     "start_time": "2017-05-05T14:48:52.990926Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:49:23.130328Z",
     "start_time": "2017-05-05T14:49:21.952942Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "top_model.load_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:49:25.233498Z",
     "start_time": "2017-05-05T14:49:25.169487Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a5edfe9126bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "model.add(top_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:51:09.655059Z",
     "start_time": "2017-05-05T14:51:09.082679Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2222 images belonging to 2 classes.\n",
      "Found 222 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-05T14:51:18.727058Z",
     "start_time": "2017-05-05T14:51:16.130697Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., epochs=50, validation_steps=222, steps_per_epoch=138)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: expected dense_6 to have shape (None, 200) but got array with shape (16, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-039fb800ae44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     nb_val_samples=nb_validation_samples)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1875\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1876\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1615\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1616\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1298\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                     exception_prefix='model target')\n\u001b[0m\u001b[1;32m   1301\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1302\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    131\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: expected dense_6 to have shape (None, 200) but got array with shape (16, 1)"
     ]
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples\n",
    "    callbacks = [checkpoint, early]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
