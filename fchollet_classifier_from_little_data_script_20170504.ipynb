{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Transfer-Learning\" data-toc-modified-id=\"Transfer-Learning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Transfer Learning</a></div><div class=\"lev1 toc-item\"><a href=\"#save_bottlebeck_features()\" data-toc-modified-id=\"save_bottlebeck_features()-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>save_bottlebeck_features()</a></div><div class=\"lev1 toc-item\"><a href=\"#train_top_model()\" data-toc-modified-id=\"train_top_model()-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>train_top_model()</a></div><div class=\"lev1 toc-item\"><a href=\"#Transfer-Learning-&amp;-fine-tuning\" data-toc-modified-id=\"Transfer-Learning-&amp;-fine-tuning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Transfer Learning &amp; fine tuning</a></div><div class=\"lev2 toc-item\"><a href=\"#VGG16-모델-불러-오기\" data-toc-modified-id=\"VGG16-모델-불러-오기-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>VGG16 모델 불러 오기</a></div><div class=\"lev1 toc-item\"><a href=\"#[Error]-Model'-object-has-no-attribute-'add'\" data-toc-modified-id=\"[Error]-Model'-object-has-no-attribute-'add'-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>[Error] Model' object has no attribute 'add'</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "참고 자료 \n",
    "- [Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "- [classifier_from_little_data_script_1.py](https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n",
    "- [classifier_from_little_data_script_2.py](https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069)\n",
    "- [classifier_from_little_data_script_3.py](https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:21:51.458863Z",
     "start_time": "2017-05-04T22:21:51.453748Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:21:51.793133Z",
     "start_time": "2017-05-04T22:21:51.789472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFLow Version:1.1.0\n",
      "Keras Version:2.0.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(\"TensorFLow Version:\"+str(tf.__version__))\n",
    "import keras; print(\"Keras Version:\"+str(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T21:58:27.042622Z",
     "start_time": "2017-05-04T21:58:27.037495Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'dog-cat/train'\n",
    "validation_data_dir = 'dog-cat/val'\n",
    "nb_train_samples = 2222 #2000 \n",
    "nb_validation_samples = 222 #800\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save_bottlebeck_features()\n",
    "- bottleneck_features는 FC가 없는 VGG16 모델을 가지고 predict()한 값 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T21:58:27.417905Z",
     "start_time": "2017-05-04T21:58:27.412664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels(150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "    print(\"Theano : Channel First\"+str(input_shape))\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    print(\"TensorFlow : Channel Last\"+str(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:09:49.648973Z",
     "start_time": "2017-05-04T22:09:49.331823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "# build the VGG16 network\n",
    "model = applications.VGG16(include_top=False, weights='imagenet', input_shape=input_shape) ## TF / TH구분으로 inputshape는 지정 필요\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:03:07.846178Z",
     "start_time": "2017-05-04T21:58:30.639208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2222 images belonging to 2 classes.\n",
      "Found 222 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "#train_data\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "#validation_data\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
    "bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples // batch_size)\n",
    "#4분 cpu12-mem20-cost0344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?? bottleneck_features를 생성(predict)할때 FC가 없는 불완전한 모델(include_top=False)로 하는것이 맞는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:13:34.317743Z",
     "start_time": "2017-05-04T22:13:34.025668Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "    bottleneck_features_train)\n",
    "np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "    bottleneck_features_validation)\n",
    "\n",
    "#write() argument must be str, not bytes 에러시   'w' ->'wb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_top_model()\n",
    "- top_model_weights는 `FC레이어`만있는 모델을 학습한 결과의 weight\n",
    "- 학습시 사용하는 데이터는 bottleneck_features이다. \n",
    "    - bottleneck_features는 FC가 없는 VGG16 모델을 가지고 `predict()`한 값 이다. \n",
    "    - bottleneck을 사용하는 이유는 FC만 학습 한다고 해도 모델이 크면 시간이 많이 걸리므로 학습(fit)이 아닌 빠른 예측(predict) 값을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:09.303034Z",
     "start_time": "2017-05-04T22:28:09.258393Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data = np.load(open('bottleneck_features_train.npy', 'rb')) #'rb'추가\n",
    "train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "# can't multiply sequence by non-int of type 'float' : 해결책  / -> //\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:11.750121Z",
     "start_time": "2017-05-04T22:28:11.746852Z"
    }
   },
   "outputs": [],
   "source": [
    "#강제 데이터 - 라벨 수 맞춤\n",
    "train_labels = train_labels[0:2190]\n",
    "validation_labels = validation_labels[0:206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:25:23.627665Z",
     "start_time": "2017-05-04T22:25:23.619366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:20.174388Z",
     "start_time": "2017-05-04T22:28:20.135854Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:21.196322Z",
     "start_time": "2017-05-04T22:28:21.191239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:28:24.773768Z",
     "start_time": "2017-05-04T22:28:24.743969Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:30:16.640127Z",
     "start_time": "2017-05-04T22:28:53.600085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2190 samples, validate on 206 samples\n",
      "Epoch 1/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6972 - acc: 0.4886 - val_loss: 0.6910 - val_acc: 0.5485\n",
      "Epoch 2/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6934 - acc: 0.4858 - val_loss: 0.6931 - val_acc: 0.5388\n",
      "Epoch 3/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6928 - val_acc: 0.5388\n",
      "Epoch 4/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6927 - val_acc: 0.5388\n",
      "Epoch 5/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6925 - val_acc: 0.5388\n",
      "Epoch 6/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6924 - val_acc: 0.5388\n",
      "Epoch 7/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6923 - val_acc: 0.5388\n",
      "Epoch 8/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 9/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 10/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 11/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 12/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 13/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 14/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 15/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 16/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 17/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 18/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 19/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 20/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6923 - val_acc: 0.5388\n",
      "Epoch 21/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6923 - val_acc: 0.5388\n",
      "Epoch 22/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 23/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 24/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 25/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 26/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 27/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 28/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 29/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 30/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 31/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 32/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 33/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 34/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 35/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 36/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 37/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 38/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 39/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 40/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6922 - val_acc: 0.5388\n",
      "Epoch 41/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 42/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 43/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 44/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6921 - val_acc: 0.5388\n",
      "Epoch 45/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 46/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 47/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 48/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 49/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 50/50\n",
      "2190/2190 [==============================] - 1s - loss: 0.6931 - acc: 0.5073 - val_loss: 0.6920 - val_acc: 0.5388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1aa411a8d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:30:50.655955Z",
     "start_time": "2017-05-04T22:30:50.627477Z"
    }
   },
   "outputs": [],
   "source": [
    "top_model_weights_path = 'fc_model.h5'\n",
    "model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning & fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 모델 불러 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:31:33.785131Z",
     "start_time": "2017-05-04T22:31:33.451674Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:32:01.340856Z",
     "start_time": "2017-05-04T22:32:01.300809Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:32:07.671052Z",
     "start_time": "2017-05-04T22:32:07.592025Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model.load_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-04T22:32:12.829503Z",
     "start_time": "2017-05-04T22:32:12.819310Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-a5edfe9126bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "model.add(top_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Error] Model' object has no attribute 'add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
